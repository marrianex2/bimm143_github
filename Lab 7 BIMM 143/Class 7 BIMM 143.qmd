---
title: "Lab 7: Machine Learning"
author: "Marriane Allahwerdi (A16902759)"
format: pdf
---

Today we are going to learn how to apply different machine learning methods, beginning with clustering: 

The goal here is to find groups/clusters in your input data

First I will make up some data with clear groups. For this I will use the `rnorm()` function: 
```{r}
rnorm(10)
```

```{r}
hist(rnorm(10000,3))
```


```{r}
hist(c(rnorm(10000, -3), rnorm(10000,3)))
```
```{r}
n <- 10000
x <- c(rnorm(n,-3), rnorm(n,3))
hist(x)
```

```{r}
n <- 30
x <- c(rnorm(n,-3), rnorm(n,3))
hist(x)
```

```{r}
n <- 30
x <- c(rnorm(n,-3), rnorm(n,3))
y <- rev(x)

z <- cbind(x,y)
head(z)
```

```{r}
plot(z)
```

Use the `kmeans()` function setting k to 2 and nstart=20

Inspect/print the results

> Q. How many points are in each cluster?

30 points in each cluster, 60 total

> Q. What ‘component’ of your result object details
 - cluster size?
 - cluster assignment/membership?
 - cluster center?
 
> Q. Plot x colored by the kmeans cluster assignment and
 add cluster centers as blue points
 
```{r}
km <- kmeans(z, centers=2)
km
```

Results in kmeans objects `km`
```{r}
attributes(km)
```
 Cluster size?  
```{r}
km$size
```
 
Cluster Assignment/membership?
```{r}
km$cluster
```
 
Cluster center?
```{r}
km$center
```

Plot x colored by the kmeans cluster assignment and
 add cluster centers as blue points
```{r}
plot(z, col="red")
```
R will recycle the shorter color vector to be the same length as the longer(number of data points) in z 
```{r}
plot(z, col=c("red", "blue") )
```
 
```{r}
plot(z, col=c( 1,2) )
```

```{r}
plot(z, col=km$cluster)
```

We can use the `points()` fucntion to add new points to an existing plot...like the cluster centers. 
```{r}
plot(z, col=km$cluster)
points(km$centers, col="blue", pch=15, cex=3)
```

> Q. Can you run kmeans() and ask for 4 clusters please and plot the results like we have done above?

```{r}
km4 <- kmeans(z, centers=4)
plot(z, col=km$cluster)
points(km4$centers, col="blue", pch=15, cex=1.5)
```

## Hierarchical Clustering

Let's take our same data `z` and see how hclust works. 

First we need a distance matrix of our data to be clsutered. 
```{r}
d <- dist(z)
hc <- hclust(d)
hc
```

```{r}
plot(hc)
abline(h=8, col="red")
```

I can get my cluster membership vector by "cutting the tree" with the `cutree()` function like so: 
```{r}
grps <-cutree(hc, h=8)
grps
```

> Q. Can you plot `z` colored by our hclus results: 

```{r}
plot(z, col=grps)
```

LAB QUESTIONS 

## PCA of UK food data

```{r}
url <- "https://tinyurl.com/UK-foods"
x <- read.csv(url, row.names=1)
head(x)
```

```{r}
dim(x)
```

> Q1. How many rows and columns are in your new data frame named x? What R functions could you use to answer this questions?

There are 17 rows and 4 columns. 

```{r}
x <- read.csv(url, row.names=1)
head(x)
```

> Q2. Which approach to solving the ‘row-names problem’ mentioned above do you prefer and why? Is one approach more robust than another under certain circumstances?

I prefer the second method because it is more generalized than the first dataset. The other code shows different parts of the data when run again while the first method is more clear in showing the information.  


```{r}
barplot(as.matrix(x), beside=T, col=rainbow(nrow(x)))
```

> Q3: Changing what optional argument in the above barplot() function results in the following plot?

Changing Beside=T to Beside=F as seen below. 

```{r}
barplot(as.matrix(x), beside=F, col=rainbow(nrow(x)))
```

A so-called "Pairs" plot can be useful for small datasets like this one

```{r}
pairs(x, col=rainbow(10), pch=16)
```

> Q5: Generating all pairwise plots may help somewhat. Can you make sense of the following code and resulting figure? What does it mean if a given point lies on the diagonal for a given plot?

A `pairs()` function creates a scatterplot matrix that can be used to visualize pairwise relationships in the dataset. The diagonal represents each variable plotted against itself, these points are not that valuable for analysis. 

> Q6. What is the main differences between N. Ireland and the other countries of the UK in terms of this data-set?

It is hard to see structure and trends in even this small data-set. We can't tell what it means if a point lies on the diagonal compared for a given plot. 

## PCA to the rescue 

Lets see how PCA deals with this dataset. The main function in base R to do PCA is called `prcomp`

```{r}
pca <- prcomp(t(x))
summary(pca)
```

Let's see what is inside this `pca` object that we created from running `prcomp` 

```{r}
attributes(pca)
```
```{r}
pca$x
```

> Q7. Complete the code below to generate a plot of PC1 vs PC2. The second line adds text labels over the data points.

```{r}
# Plot PC1 vs PC2
plot(pca$x[,1], pca$x[,2], 
     xlab="PC1", ylab="PC2", xlim=c(-270,500))
text(pca$x[,1], pca$x[,2], colnames(x))
```

> Q8. Customize your plot so that the colors of the country names match the colors in our UK and Ireland map and table at start of this document.

```{r}
plot(pca$x[,1], pca$x[,2], col=c("black", "red", "blue", "darkgreen"), pch=16, xlab="PC1 (67.4%)", ylab="PC2 (29%")
```

```{r}
v <- round( pca$sdev^2/sum(pca$sdev^2) * 100 )
v
```
```{r}
## or the second row here...
z <- summary(pca)
z$importance
```
```{r}
barplot(v, xlab="Principal Component", ylab="Percent Variation")
```

```{r}
## Lets focus on PC1 as it accounts for > 90% of variance 
par(mar=c(10, 3, 0.35, 0))
barplot( pca$rotation[,1], las=2 )
```


> Q9: Generate a similar ‘loadings plot’ for PC2. What two food groups feature prominantely and what does PC2 mainly tell us about?

The 2 main food groups featured are fresh_potatoes among and soft_drinks. PC2 mainly tells us the second most degree of variation among the countries which appears between those two food groups as seen in the graph below. 

```{r}
par(mar=c(10, 3, 0.35, 0))
barplot( pca$rotation[,2], las=2 )
```

















